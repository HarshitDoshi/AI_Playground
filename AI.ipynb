{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52eVtvU8BjXE"
   },
   "source": [
    "# Harshit's Artificial Intelligence (AI) Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D3kMdBCZCv05"
   },
   "source": [
    "According to me, the field of AI is roughly divided into the following sub-domains:\n",
    "\n",
    "- Data Science\n",
    "- Learning\n",
    "- Robotics\n",
    "\n",
    "### Data Science\n",
    "Data science is the field which deals with the large amount of data we require and have in the worldly problems. The following things maybe roughly put in the field of data science:\n",
    "\n",
    "- Data Storage\n",
    "- Databases\n",
    "- Data Mining\n",
    "- Data Exploration\n",
    "- Big Data\n",
    "- Data Cleansing\n",
    "- Data Analysis\n",
    "- Data Visualization And Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfunfbMbYlUH"
   },
   "source": [
    "### Learning\n",
    "\n",
    "Learning is the science in which we make computers or machines learn in a way which is quite similar to how a human learns. Learning is mostly about mathematics. Statistics plays a major role in learning and hence, in general, it is also known as \"statistical learning\". When statistical learning methods are converted to computer algorithms and programs, we call it \"machine learning\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txCBDjJCYpU1"
   },
   "source": [
    "### Robotics\n",
    "\n",
    "Robotics is the science of creating machines which try to replicate how a human body works using mechanical, electrical, computer and electronic systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjEy927gHl97"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9qugXqxCr4N"
   },
   "source": [
    "## Statistical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NdofZocwCMDu"
   },
   "source": [
    "There are 2 aspects of every statistical learning problems. They are:\n",
    "\n",
    "- Input Variable\n",
    "- Output Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSmq2_0CCp4G"
   },
   "source": [
    "### Input Variables\n",
    "Input variables are the various factors affecting the _output_ or the _result_ of any statistical learning problem. They are also known as _predictors_, _independent variables_ or _features_.\n",
    "\n",
    "Example:\n",
    "\n",
    "In the advertising budget problem, the budget of **television based advertisements**, **radio based advertisements** and **newspaper based advertisements** can be shown by variables, **$X_{1}$**, **$X_{2}$** and **$X_{3}$** respectively.\n",
    "\n",
    "Factors | Variables\n",
    "--- | ---\n",
    "TV | $X_{1}$\n",
    "RADIO | $X_{2}$\n",
    "NEWSPAPER | $X_{3}$\n",
    "\n",
    "These are the input variables for the advertising budget problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPBgHCCoHfZh"
   },
   "source": [
    "### Output Variables\n",
    "\n",
    "The final result of a prediction or learning problem. It is the outcome of the whole problem. The output variables are dependent on the input variables for that particular problem. They are also known as _responses_ or _dependent variables_.\n",
    "\n",
    "Example:\n",
    "In the advertising budget problem, after we have predicted the **sales** from the given input variables, using one of the many statistical learning methods, we get the resultant **sales**. We can represent that as **$Y$**.\n",
    "\n",
    "Result | Variable\n",
    "--- | ---\n",
    "Sales | $Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4SzvTaVDMqEM"
   },
   "source": [
    "### Relationship between the input variables and the output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AYj6Yf3nI4ci"
   },
   "source": [
    "Thus, we observe a _quantitative response_ ($Y$), due to _$p$_ different _predictors_ ($X_{1}, X_{2}, X_{3}, \\cdots , X_{p}$).\n",
    "\n",
    "Summing up the $p$ predictors into one, we get:\n",
    "$$\n",
    "X = X_{1} + X_{2} + X_{3} + \\cdots + X_{p}\n",
    "$$\n",
    "\n",
    "Also, $X$ affects $Y$. Thus, there is some relationship between $X$ and $Y$.\n",
    "\n",
    "It can be shown by the following equation:\n",
    "$$\n",
    "Y = f(X) + \\varepsilon\n",
    "$$\n",
    "\n",
    "where,\n",
    "- $f(X)$ is a fixed but unknown function which is dependent on $X$,\n",
    "- $\\varepsilon$ is the _error term_ which is independent of $X$ and has a mean of _zero_. Errors are **_positive_** if the observation lies **above** the _curve of $f(X)$_ and **_negative_** if they lie **below** it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sW1rFAy1MYVo"
   },
   "source": [
    "Our goal is to find an estimate of $f$, which would fit $X$ to $Y$ with the minimum error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqg7A-ZDMk7T"
   },
   "source": [
    "### Why estimate $f$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pziy3rmDM3SP"
   },
   "source": [
    "Our motive behind estimating $f$ can be one (or both) of the following:\n",
    "1. Prediction\n",
    "2. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKctojwhfRnt"
   },
   "source": [
    "### Prediction\n",
    "\n",
    "Prediction means trying to estimate a result for the future based on the past. We humans predict something by acknowledging the data from the past and trying to guess or estimate the future. Similarly, machines can be taught using various learning techniques and they can then estimate or guess the future. Examples of prediction or domains where prediction can be applied are:\n",
    "\n",
    "- Weather forecasts\n",
    "- Disaster analysis\n",
    "- Stock markets\n",
    "- Traffic forecast\n",
    "\n",
    "For prediction, we have a set of _inputs_, $X$, readily available. The _output_, $Y$, is not available to us.\n",
    "\n",
    "We can then predict $Y$ as follows:\n",
    "$$\n",
    "\\hat{Y} = \\hat{f}(X)\n",
    "$$\n",
    "\n",
    "Where,\n",
    "- $\\hat{Y}$ is our prediction for $Y$, and,\n",
    "- $\\hat{f}(X)$ is our estimate for $f(X)$.\n",
    "\n",
    "Here, the error term, $\\varepsilon$, averages to zero.\n",
    "\n",
    "The accuracy of $\\hat{Y}$, as a prediction of $Y$, depends on 2 quantities,\n",
    "1. Reducible error\n",
    "2. Irreducible error\n",
    "\n",
    "In general, $\\hat{f}$ will not be an accurate estimate for $f$, and it will introduce a _reducible error_. We can reduce or minimize it using better statistical learning methods.\n",
    "\n",
    "Even though we perfectly estimate $f$ such that $\\hat{Y} = f(X)$, our prediction would still contain an error, because, $Y$ is also a function of $\\varepsilon$. Variability associated with $\\varepsilon$ also affects the accuracy of our prediction. This is the _irreducible error_. We cannot remove it how much ever we try.\n",
    "\n",
    "**Why is the irreducible error > 0?**\n",
    "\n",
    "$\\varepsilon$ may contain _unmeasurable variables_ that are useful in predicting $Y$. It may also contain _unmeasurable variations_.\n",
    "\n",
    "$$\n",
    "E(Y - \\hat{Y})^{2} = E[f(X) + \\varepsilon - \\hat{f}(X)]^{2} = [f(X) - \\hat{f}(X)]^{2} + var(\\varepsilon)\n",
    "$$\n",
    "\n",
    "where,\n",
    "- $E(Y - \\hat{Y})^{2}$ is the _expected value_,\n",
    "- $[f(X) - \\hat{f}(X)]^{2}$ is the _squared difference_ between the predicted and actual value of $Y$. It is _reducible_ in nature.\n",
    "- $var({\\varepsilon})$ is the variance associated with $\\varepsilon$. It is irreducible in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SES4UO2Vx2oY"
   },
   "source": [
    "### Inference\n",
    "\n",
    "We are often interested in knowing how the output of a problem is affected by the input. We want to know how $Y$ is affected as $X = X_{1} + X_{2} + X_{3} + \\cdots + X_{p}$ changes.\n",
    "\n",
    "Thus, we want to understand the relationship between $X$ and $Y$.\n",
    "\n",
    "Here, $\\hat{f}$ cannot be treated as a \"_black box_\". We need the exact form of $\\hat{f}$.\n",
    "\n",
    "**We may want to infer,**\n",
    "- which predictors are _associated_ with the response,\n",
    "- what the _relationship between each_ predictor and the response is (positive, negative, etc.).\n",
    "- can the relationship between $Y$ and each predictor be adequately summarized using a linear equation or is the relationship more complicated (quadratic, cubic, etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPHTH1Zv1P1I"
   },
   "source": [
    "### How do we estimate $f$?\n",
    "\n",
    "To estimate $f$, we need to teach our method. To teach, we have some data which we call as the _training data_. Training data is the dataset or part of the dataset which is used to train or teach the method on how to estimate $f$.\n",
    "\n",
    "**Characteristics of training data:**\n",
    "\n",
    "- $i$ denotes the $i^{th}$ observation out of the total $n$ observations.\n",
    "- $j$ denotes the $j^{th}$ predictor out of the $p$ total predictors.\n",
    "\n",
    "Thus, $x_{ij}$ is the $i^{th}$ observation of the $j^{th}$ predictor.\n",
    "\n",
    "Thus, $y_{i}$ is the response variable for the $i^{th}$ observation.\n",
    "\n",
    "Thus,\n",
    "\n",
    "Our training data set consists of,\n",
    "$$\n",
    "{(x_{1}, y_{1}), (x_{2}, y_{2}, \\cdots, (x_{n}, y_{n}))}\n",
    "$$\n",
    "where,\n",
    "$$\n",
    "x_{i} = (x_{i1}, x_{i2}, \\cdots, x_{ip})^{T}\n",
    "$$\n",
    "\n",
    "Our goal is to apply a statistical learning method to our training data in order to estimate the unknown fucntion $f$.\n",
    "\n",
    "We want to find a function $f$ such that,\n",
    "$Y \\approx \\hat{f}(X)$, for any observation $(X, Y)$.\n",
    "\n",
    "Most statistical methods for this task can be classified into:\n",
    "\n",
    "1. Parametric methods\n",
    "2. Non-parametrix methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7oWjpFFT7JL"
   },
   "source": [
    "### Parametric Methods\n",
    "\n",
    "**Involves a 2-step, _model based_ approach.**\n",
    "\n",
    "**STEP 1:**\n",
    "\n",
    "We, first, make an assumption about the functional form, or shape, of $f$.\n",
    "\n",
    "One very simple, and maybe the first assumption we may make for any given problem, would be that $f$ is _linear_ in $X$:\n",
    "\n",
    "$$\n",
    "f(X) = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\cdots + \\beta_{p}X_{p}\n",
    "$$\n",
    "\n",
    "This is a _linear model_.\n",
    "\n",
    "Linear models are very simple. Instead of having to estimate an entirely arbitrary $p$-dimensional function $f(X)$, one only needs to estimate the $p + 1$ coefficients, $\\beta_{0}, \\beta_{1}, \\beta_{2}, \\cdots, \\beta_{p}$.\n",
    "\n",
    "**STEP 2:**\n",
    "\n",
    "After a model is selected, a _procedure_ needs to be selected to _fit_ or _train_ the model. In case of our linear model, we need to estimate the parameters $\\beta_{0}, \\beta_{1}, \\beta_{2}, \\cdots, \\beta_{p}$ such that,\n",
    "\n",
    "$$\n",
    "Y \\approx \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\cdots + \\beta_{p}X_{p}\n",
    "$$\n",
    "\n",
    "The most common approach to fitting the model is referred to as \"**_(ordinary) least squares_**\". However, _least squares_ is one of the many possible methods to fit a linear model.\n",
    "\n",
    "**Thus, a _parametric method_ reduces the problem of estimating $f$ down to one of estimating a set of parameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "A **_Decision Tree_** is a very basic model used in machine learning. It is not very accurate for predictions and much more powerful models do exist, but they are very easy to understand and sometimes also act as building blocks for the more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a simple decision tree:\n",
    "\n",
    "![Simple Decision Tree (PNG)](/res/simple_decision_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of recognizing patterns from data is called **fitting** or **training**. The data used to **train** or **fit** is called as **training data**.\n",
    "\n",
    "There can be more complex, and thus more accurate decision trees. An example of a more accurately predicting decision tree is given below:\n",
    "\n",
    "![Deeper Decision Tree (PNG)](/res/deeper_decision_tree.png)\n",
    "\n",
    "This tree gives more accurate predictions than say a tree like the one below:\n",
    "\n",
    "![Less Deep Decision Tree (PNG)](/res/less_deep_decision_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deeper decision trees have more '_splits_'. _Splits_ allow us to introduce more number of _factors_ in our decision making process. More the number of factors, better the prediction. The last node of the tree, where we obtain our prediction, is known as the **leaf** node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use some data to try out our new tricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is an open-source Python data analysis library. We can use Pandas in our Python code by importing it. We generally import Pandas using the abbreviation **pd**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature of Pandas is its **_DataFrame_** object. A DataFrame is a container which holds the type of data which is similar to a table or an Excel sheet or a SQL table. This DataFrame object can then allow us to do a lot of things on the data using powerful methods in the Pandas library.\n",
    "\n",
    "As an example, we will be looking at data about home prices in Melbourne, Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13580.000000</td>\n",
       "      <td>1.358000e+04</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13518.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>7130.000000</td>\n",
       "      <td>8205.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.937997</td>\n",
       "      <td>1.075684e+06</td>\n",
       "      <td>10.137776</td>\n",
       "      <td>3105.301915</td>\n",
       "      <td>2.914728</td>\n",
       "      <td>1.534242</td>\n",
       "      <td>1.610075</td>\n",
       "      <td>558.416127</td>\n",
       "      <td>151.967650</td>\n",
       "      <td>1964.684217</td>\n",
       "      <td>-37.809203</td>\n",
       "      <td>144.995216</td>\n",
       "      <td>7454.417378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.955748</td>\n",
       "      <td>6.393107e+05</td>\n",
       "      <td>5.868725</td>\n",
       "      <td>90.676964</td>\n",
       "      <td>0.965921</td>\n",
       "      <td>0.691712</td>\n",
       "      <td>0.962634</td>\n",
       "      <td>3990.669241</td>\n",
       "      <td>541.014538</td>\n",
       "      <td>37.273762</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>4378.581772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.500000e+05</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>3044.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.856822</td>\n",
       "      <td>144.929600</td>\n",
       "      <td>4380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.030000e+05</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>3084.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.802355</td>\n",
       "      <td>145.000100</td>\n",
       "      <td>6555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058305</td>\n",
       "      <td>10331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>433014.000000</td>\n",
       "      <td>44515.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "      <td>21650.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rooms         Price      Distance      Postcode      Bedroom2  \\\n",
       "count  13580.000000  1.358000e+04  13580.000000  13580.000000  13580.000000   \n",
       "mean       2.937997  1.075684e+06     10.137776   3105.301915      2.914728   \n",
       "std        0.955748  6.393107e+05      5.868725     90.676964      0.965921   \n",
       "min        1.000000  8.500000e+04      0.000000   3000.000000      0.000000   \n",
       "25%        2.000000  6.500000e+05      6.100000   3044.000000      2.000000   \n",
       "50%        3.000000  9.030000e+05      9.200000   3084.000000      3.000000   \n",
       "75%        3.000000  1.330000e+06     13.000000   3148.000000      3.000000   \n",
       "max       10.000000  9.000000e+06     48.100000   3977.000000     20.000000   \n",
       "\n",
       "           Bathroom           Car       Landsize  BuildingArea    YearBuilt  \\\n",
       "count  13580.000000  13518.000000   13580.000000   7130.000000  8205.000000   \n",
       "mean       1.534242      1.610075     558.416127    151.967650  1964.684217   \n",
       "std        0.691712      0.962634    3990.669241    541.014538    37.273762   \n",
       "min        0.000000      0.000000       0.000000      0.000000  1196.000000   \n",
       "25%        1.000000      1.000000     177.000000     93.000000  1940.000000   \n",
       "50%        1.000000      2.000000     440.000000    126.000000  1970.000000   \n",
       "75%        2.000000      2.000000     651.000000    174.000000  1999.000000   \n",
       "max        8.000000     10.000000  433014.000000  44515.000000  2018.000000   \n",
       "\n",
       "          Lattitude    Longtitude  Propertycount  \n",
       "count  13580.000000  13580.000000   13580.000000  \n",
       "mean     -37.809203    144.995216    7454.417378  \n",
       "std        0.079260      0.103916    4378.581772  \n",
       "min      -38.182550    144.431810     249.000000  \n",
       "25%      -37.856822    144.929600    4380.000000  \n",
       "50%      -37.802355    145.000100    6555.000000  \n",
       "75%      -37.756400    145.058305   10331.000000  \n",
       "max      -37.408530    145.526350   21650.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving filepath to a variable for easier access\n",
    "melb_data_filepath = 'melb_data.csv'\n",
    "# Read data from a CSV file and store it in a DataFrame object called melb_data\n",
    "melb_data = pd.read_csv(melb_data_filepath)\n",
    "# Print a summary of data in Melbourne data\n",
    "melb_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting data descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table shows 8 numbers for all the columns in the original dataset.\n",
    "\n",
    "The **count** column shows the number of rows containing non-missing values. Missing values are those for which there is no possible data. For example, the count for bedroom 2 in a 1 bedroom house will not be available and thus missing.\n",
    "\n",
    "The **mean** is an average of the values.\n",
    "\n",
    "**std** is for the standard deviation of the values. Standard deviation shows us how numerically the data is spread out. For more about standard deviation, refer to the basic statistics section.\n",
    "\n",
    "Sort the data in ascending order. The first value is the **min** value. **25%**, **50%** and **75%** are percentile values (_$x^{th}$ percentile_). They indicate the values which are bigger than $x$% of the values in the dataset and smaller than $(x - 100)$% of the values in the dataset. **max** is the largest number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Melbourne housing problem dataset has a lot of variables in it. It makes it difficult to grasp the data and understand it. We need to narrow down the number of columns (or factors) to those which actually matter. We will start by doing this intuitively.\n",
    "\n",
    "The **columns** property of the DataFrame object allows us to see a list of all the columns we have in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will continue our Python code from the last cell containing Python code\n",
    "melb_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Melbourne dataset contains rows with missing values. We will learn how to handle missing values later, so for now we will just discard (or drop) those rows. To do so, we will use the **dropna** method. The **na** stands for **Not Available**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_data = melb_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the prediction target\n",
    "\n",
    "Using Pandas, one can pull out a single variable using the _dot-notation_. This single column is stored in a **_Series_**. It is similar to a DataFrame but with only a single column.\n",
    "\n",
    "We will use the _dot-notation_ to select a column which is called a **prediction target**. Our prediction target here would be the house prices. By convention, the prediction target is stored in a variable called ```y```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = melb_data.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing features\n",
    "\n",
    "The"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
